refactor(models): Introduce unified, type-safe data architecture

This commit introduces a fundamental refactoring of the data models used by the AI agents, moving from a fragmented, hard-coded structure to a unified, scalable, and type-safe architecture.

The previous models were brittle, had significant code duplication, and were not designed to scale as new requirements or agent types were introduced. This new architecture establishes a clear, robust "data contract" for the entire system.

Key Changes:

- **Unified Input Model:**
  - `ProcurementRequest` and `ExtendedProcurementRequest` have been consolidated into a single, comprehensive `ProcurementRequest` model. This serves as the single source of truth for all incoming procurement data.

- **Generic, Reusable Components:**
  - Introduced a generic `Requirement` model to represent any requirement from any source (Oslomodell, Milj√∏krav, etc.), eliminating duplication.
  - A new `BaseAssessmentResult` class standardizes metadata (confidence, timestamps, etc.) across all agent outputs, ensuring consistency.

- **Rich, Domain-Specific Results:**
  - Agent-specific result models like `OslomodellAssessmentResult` now inherit from `BaseAssessmentResult`.
  - They use rich, nested Pydantic models (e.g., `ApprenticeshipRequirement`) instead of untyped dictionaries, providing full type safety and clarity.

- **Hybrid Agent Strategy:**
  - The `OslomodellAgent` has been refactored to follow a hybrid pattern.
  - The LLM's primary role is now **interpretation**: identifying which requirement *codes* apply based on the procurement context.
  - A deterministic **enrichment** step then uses these codes to fetch the full, detailed requirement data from a reliable source of truth (the database). This makes the agent faster, more reliable, and less prone to hallucination.

This new architecture makes the system significantly more robust, maintainable, and easier to extend in the future.